<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html lang="en-US">
<head>
	<meta http-equiv="content-type" content="text/html; charset=UTF-8" />
	<link rel="canonical" href="TheTruePrisonersDilemma.html" />
	<title>The True Prisoner’s Dilemma  </title>
	<meta name="viewport" content="width=device-width, initial-scale=1"/>
	<link rel='stylesheet' href='wiki/pub/skins/readthesequences/skin.css' type='text/css' />
	<!--HTMLHeader--><style type='text/css'><!--a[href^='http://archive.is/timegate/'] { opacity: 0.5;  }

.footnote_block_begin { 
	width: 160px; 
	border-bottom: 1px solid blue;
	margin-bottom: 0.5em;
}
div.footnote {
	margin: 0 3em 0.5em 0;
	padding-left: 2em;
	font-size: 0.9em;
	position: relative;
}
div.footnote .footnote-number {
	position: absolute;
	left: 0;
	width: 1.5em;
	text-align: right;
}
div.footnote .footnote-number::after {
	content: '.';
}
.num { position: relative; font-size: 0.7em; bottom: 0.5em; right: 0.1em; margin-left: 0.15em; }
.frasl { font-size: 1.15em; line-height: 1; }
.denom { position: relative; font-size: 0.7em; top: 0.05em; left: 0.1em; }

#pd-table { border-collapse: collapse; margin-bottom: 1.5em; border: #333; }
#pd-table td { text-align: center; vertical-align: middle; padding: 3px 12px 0px 12px; }

--></style><meta http-equiv='Content-Type' content='text/html; charset=utf-8' /><link href="wiki/uploads/favicon.png" type="image/png" rel="shortcut icon" /><link rel='preload' href='wiki/fonts/font_files/GaramondPremierProSubhead/GaramondPremierProSubhead-Medium.otf' type='font/otf' as='font' crossorigin />
<link rel='preload' href='wiki/fonts/font_files/ProximaNova/ProximaNova-Thin.otf' type='font/otf' as='font' crossorigin />
  <meta name='robots' content='index,follow' />

</head>
<body>
<!--PageText-->
<div id='wikitext'>
<div class='article-talk-selector' > 
<p><a target='blank'  class='wikilink' href='The-True-Prisoners-Dilemma%3Faction=source' title='View PmWiki source for “The True Prisoner’s Dilemma”'>Source</a><a target='blank'  class='wikilink' href='The-True-Prisoners-Dilemma%3Faction=markdown' title='View “The True Prisoner’s Dilemma” in Markdown format'>Markdown</a> · <a rel='nofollow'  class='wikilink' href='Talk/The-True-Prisoners-Dilemma.html' title='View the Talk page for “The True Prisoner’s Dilemma”'>Talk</a>
</p></div>
<div class='nav_menu' > 
<p><a class='wikilink' href='index.html'>Home</a><a class='wikilink' href='About.html'>About</a><a class='urllink' href='Search.html' rel='nofollow'>Search</a><a class='wikilink' href='Contents.html'>Contents</a>
</p></div>
<h1>The True Prisoner’s Dilemma</h1>
<p  style='text-align: center;'> ❦
</p>
<p>It occurred to me one day that the standard visualization of the <a class='urllink' href='http://en.wikipedia.org/wiki/Prisoner%27s%20Dilemma' rel='nofollow'>Prisoner’s Dilemma</a> is fake.
</p>
<p>The core of the Prisoner’s Dilemma is this symmetric payoff matrix:
</p>
<table id='pd-table' border='1' ><tr ><td  class='left'>&nbsp;</td><td  class='left'>1 : <em>C</em></td><td  class='left'>1 : <em>D</em></td></tr>
<tr ><td  class='left'>2 : <em>C</em></td><td  class='left'>(3, 3)</td><td  class='left'>(5, 0)</td></tr>
<tr ><td  class='left'>2 : <em>D</em></td><td  class='left'>(0, 5)</td><td  class='left'>(2, 2)</td></tr>
</table>
<p>Player 1, and Player 2, can each choose <em>C</em> or <em>D</em>. Player 1’s and Player 2’s utilities for the final outcome are given by the first and second number in the pair. For reasons that will become apparent, “<em>C</em>” stands for “cooperate” and <em>D</em> stands for “defect.”
</p>
<p>Observe that a player in this game (regarding themselves as the first player) has this preference ordering over outcomes: <span class='equation'>(<em>D</em>,<em>C</em>) &gt; (<em>C</em>,<em>C</em>) &gt; (<em>D</em>,<em>D</em>) &gt; (<em>C</em>,<em>D</em>)</span>.
</p>
<p>Option <em>D</em>, it would seem, dominates <em>C</em>: If the other player chooses <em>C</em>, you prefer <span class='equation'>(<em>D</em>,<em>C</em>)</span> to <span class='equation'>(<em>C</em>,<em>C</em>)</span>; and if the other player chooses <em>D</em>, you prefer <span class='equation'>(<em>D</em>,<em>D</em>)</span> to <span class='equation'>(<em>C</em>,<em>D</em>)</span>. So you wisely choose <em>D</em>, and as the payoff table is symmetric, the other player likewise chooses <em>D</em>.
</p>
<p>If only you’d both been less wise! You <em>both</em> prefer <span class='equation'>(<em>C</em>,<em>C</em>)</span> to <span class='equation'>(<em>D</em>,<em>D</em>)</span>. That is, you both prefer mutual cooperation to mutual defection.
</p>
<p>The Prisoner’s Dilemma is one of the great foundational issues in decision theory, and enormous volumes of material have been written about it. Which makes it an audacious assertion of mine, that the usual way of <em>visualizing</em> the Prisoner’s Dilemma has a severe flaw, at least if you happen to be human.
</p>
<p>The classic visualization of the Prisoner’s Dilemma is as follows: you are a criminal, and you and your confederate in crime have both been captured by the authorities.
</p>
<p>Independently, without communicating, and without being able to change your mind afterward, you have to decide whether to give testimony against your confederate <span class='equation'>(<em>D</em>)</span> or remain silent <span class='equation'>(<em>C</em>)</span>.
</p>
<p>Both of you, right now, are facing one-year prison sentences; testifying (<em>D</em>) takes one year off your prison sentence, and adds two years to your confederate’s sentence.
</p>
<p>Or maybe you and some stranger are, only once, and without knowing the other player’s history or finding out who the player was afterward, deciding whether to play <em>C</em> or <em>D</em>, for a payoff in dollars matching the standard chart.
</p>
<p>And, oh yes—in the classic visualization you’re supposed to <em>pretend that you’re entirely selfish</em>, that you don’t care about your confederate criminal, or the player in the other room.
</p>
<p>It’s this last specification that makes the classic visualization, in my view, fake.
</p>
<p>You <a class='urllink' href='https://www.greaterwrong.com/lw/il/hindsight_bias/' rel='nofollow'>can’t avoid hindsight bias</a> by instructing a jury to pretend not to know the real outcome of a set of events. And without a complicated effort backed up by considerable knowledge, a neurologically intact human being cannot pretend to be genuinely, truly selfish.
</p>
<p>We’re born with a sense of fairness, honor, empathy, sympathy, and even altruism—the result of our ancestors’ <a class='wikilink' href='AdaptationExecutersNotFitnessMaximizers.html'>adapting</a> to play the <em>iterated</em> Prisoner’s Dilemma. We don’t really, truly, absolutely and entirely prefer <span class='equation'>(<em>D</em>,<em>C</em>)</span> to <span class='equation'>(<em>C</em>,<em>C</em>)</span>, though we may entirely prefer <span class='equation'>(<em>C</em>,<em>C</em>)</span> to <span class='equation'>(<em>D</em>,<em>D</em>)</span> and <span class='equation'>(<em>D</em>,<em>D</em>)</span> to <span class='equation'>(<em>C</em>,<em>D</em>)</span>. The thought of our confederate spending three years in prison does not entirely fail to move us.
</p>
<p>In that locked cell where we play a simple game under the supervision of economic psychologists, we are not entirely and absolutely without sympathy for the stranger who might cooperate. We aren’t entirely happy to think that we might defect and the stranger cooperate, getting five dollars while the stranger gets nothing.
</p>
<p>We fixate instinctively on the <span class='equation'>(<em>C</em>,<em>C</em>)</span> outcome and search for ways to argue that it should be the mutual decision: “How can we ensure mutual cooperation?” is the instinctive thought. Not “How can I trick the other player into playing <em>C</em> while I play <em>D</em> for the maximum payoff?”
</p>
<p>For someone with an impulse toward altruism, or honor, or fairness, the Prisoner’s Dilemma doesn’t really have the critical payoff matrix—whatever the financial payoff to individuals. The outcome <span class='equation'>(<em>C</em>,<em>C</em>)</span> is preferable to the outcome <span class='equation'>(<em>D</em>,<em>C</em>)</span>, and the key question is whether the other player sees it the same way.
</p>
<p>And no, you can’t instruct people being initially introduced to game theory to pretend they’re completely selfish—any more than you can instruct human beings being introduced to <a class='wikilink' href='AnthropomorphicOptimism.html'>anthropomorphism</a> to pretend they’re expected paperclip maximizers.
</p>
<p>To construct the True Prisoner’s Dilemma, the situation has to be something like this:
</p>
<p>Player 1: Human beings, Friendly AI, or other humane intelligence.
</p>
<p>Player 2: Unfriendly AI, or an alien that <a class='wikilink' href='SortingPebblesIntoCorrectHeaps.html'>only cares about sorting pebbles</a>.
</p>
<p>Let’s suppose that four billion human beings—not the whole human species, but a significant part of it—are currently progressing through a fatal disease that can only be cured by substance <em>S</em>.
</p>
<p>However, substance <em>S</em> can only be produced by working with a paperclip maximizer from another dimension—substance <em>S</em> can also be used to produce paperclips. The paperclip maximizer only cares about the number of paperclips in its own universe, not in ours, so we can’t offer to produce or threaten to destroy paperclips here. We have never interacted with the paperclip maximizer before, and will never interact with it again.
</p>
<p>Both humanity and the paperclip maximizer will get a single chance to seize some additional part of substance <em>S</em> for themselves, just before the dimensional nexus collapses; but the seizure process destroys some of substance <em>S</em>.
</p>
<p>The payoff matrix is as follows:
</p>
<table border='1' style='border-collapse:collapse; margin-bottom:1.5em; border-color:#333; ' ><tr><td align='center' valign='middle' style='padding: 3px 12px 0px 12px; ' > &nbsp;
</td><td align='center' valign='middle' style='padding: 3px 12px 0px 12px; ' > 1 : <em>C</em>
</td><td align='center' valign='middle' style='padding: 3px 12px 0px 12px; ' > 1 : <em>D</em>
</td></tr><tr><td align='center' valign='middle' style='padding: 3px 12px 0px 12px; ' > 2 : <em>C</em>
</td><td align='center' valign='middle' style='padding: 3px 12px 0px 12px; letter-spacing:normal; ' > (+2 billion human lives saved, <br />+2 paperclips gained)
</td><td align='center' valign='middle' style='padding: 3px 12px 0px 12px;letter-spacing:normal;  ' > (+3 billion lives, <br />+0 paperclips)
</td></tr><tr><td align='center' valign='middle' style='padding: 3px 12px 0px 12px; ' > 2 : <em>D</em>
</td><td align='center' valign='middle' style='padding: 3px 12px 0px 12px; letter-spacing:normal; ' > (+0 lives, <br />+3 paperclips)
</td><td align='center' valign='middle' style='padding: 3px 12px 0px 12px; letter-spacing:normal; ' > (+1 billion lives, <br />+1 paperclip)
</td></tr></table>
<p>I’ve chosen this payoff matrix to produce a sense of <em>indignation</em> at the thought that the paperclip maximizer wants to trade off billions of human lives against a couple of paperclips. Clearly the paperclip maximizer <em>should</em> just let us have all of substance <em>S</em>. But a paperclip maximizer doesn’t do what it <em>should</em>; it just maximizes paperclips.
</p>
<p>In this case, we <em>really do</em> prefer the outcome <span class='equation'>(<em>D</em>,<em>C</em>)</span> to the outcome <span class='equation'>(<em>C</em>,<em>C</em>)</span>, leaving aside the actions that produced it. We would vastly rather live in a universe where 3 billion humans were cured of their disease and no paperclips were produced, rather than sacrifice a billion human lives to produce 2 paperclips. It doesn’t seem <em>right</em> to cooperate, in a case like this. It doesn’t even seem <em>fair</em>—so great a sacrifice by us, for so little gain by the paperclip maximizer? And let us specify that the paperclip-agent experiences no pain or pleasure—it just outputs actions that steer its universe to contain more paperclips. The paperclip-agent will experience no pleasure at gaining paperclips, no hurt from losing paperclips, and no painful sense of betrayal if we betray it.
</p>
<p>What do you do then? Do you cooperate when you really, definitely, truly and absolutely do want the highest reward you can get, and you don’t care a tiny bit by comparison about what happens to the other player? When it seems <em>right</em> to defect even if the other player cooperates?
</p>
<p>That’s what the payoff matrix for the <em>true</em> Prisoner’s Dilemma looks like—a situation where <span class='equation'>(<em>D</em>,<em>C</em>)</span> seems <em>righter</em> than <span class='equation'>(<em>C</em>,<em>C</em>)</span>.
</p>
<p>But all the rest of the logic—everything about what happens if both agents think that way, and both agents defect—is the same. For the paperclip maximizer cares as little about human deaths, or human pain, or a human sense of betrayal, as we care about paperclips. Yet we both prefer <span class='equation'>(<em>C</em>,<em>C</em>)</span> to <span class='equation'>(<em>D</em>,<em>D</em>)</span>.
</p>
<p>So if you’ve ever prided yourself on cooperating in the Prisoner’s Dilemma… or questioned the verdict of classical game theory that the “<a class='wikilink' href='NewcombsProblemAndRegretOfRationality.html'>rational</a>” choice is to defect… then what do you say to the True Prisoner’s Dilemma above?
</p>
<p><em>P.S.:</em> In fact, I <em>don’t</em> think rational agents should always defect in one-shot Prisoner’s Dilemmas, when the other player will cooperate if it expects you to do the same. I think there are situations where two agents can rationally achieve <span class='equation'>(<em>C</em>,<em>C</em>)</span> as opposed to <span class='equation'>(<em>D</em>,<em>D</em>)</span>, and reap the associated benefits.<span class='citation'><a id='citation1'></a><a href='TheTruePrisonersDilemma.html#footnote1'>1</a></span>
</p>
<p>I’ll explain some of my reasoning when I discuss <a class='wikilink' href='NewcombsProblemAndRegretOfRationality.html'>Newcomb’s Problem</a>. But we can’t talk about whether <a class='urllink' href='https://intelligence.org/files/TDT.pdf' rel='nofollow'>rational cooperation is possible</a> in this dilemma until we’ve dispensed with the visceral sense that the <span class='equation'>(<em>C</em>,<em>C</em>)</span> outcome is <em>nice</em> or <em>good</em> in itself. We have to see past the prosocial <a class='wikilink' href='SneakingInConnotations.html'>label</a> “mutual cooperation” if we are to grasp the math. If you intuit that <span class='equation'>(<em>C</em>,<em>C</em>)</span> trumps <span class='equation'>(<em>D</em>,<em>D</em>)</span> from Player 1’s perspective, but don’t intuit that <span class='equation'>(<em>D</em>,<em>C</em>)</span> also trumps <span class='equation'>(<em>C</em>,<em>C</em>)</span>, you haven’t yet appreciated what makes this problem difficult.
</p>
<div class='original_lesswrong_link' class='img imgonly'> <a class='urllink' href='https://www.greaterwrong.com/lw/tn/the_true_prisoners_dilemma#comments' title='View Less Wrong discussion thread for “The True Prisoner’s Dilemma”' rel='nofollow'><img src='wiki/uploads/star.svg' alt='' /></a></div>
<div class='footnotes' >
<p><a id='footnote1'></a> <span class='footnote'> Eliezer Yudkowsky, <em>Timeless Decision Theory</em>, Unpublished manuscript (Machine Intelligence Research Institute, Berkeley, CA, 2010), <a class='urllink' href='http://intelligence.org/files/TDT.pdf' rel='nofollow'>http://intelligence.org/files/TDT.pdf</a>. </span><span class='back_to_citation_link'><a href='TheTruePrisonersDilemma.html#citation1'>↩︎</a></span>
</p></div>
<div class='bottom_nav bottom_nav_post' >
<p><a class='wikilink' href='MagicalCategories.html'>Magical Categories</a>
</p>
<p><a class='wikilink' href='Contents.html'>Top</a>
</p>
<p><a class='wikilink' href='Book-V-MereGoodness.html'>Book</a>
</p>
<p><a class='wikilink' href='ValueTheorySequence.html'>Sequence</a>
</p>
<p><a class='wikilink' href='SympatheticMinds.html'>Sympathetic Minds</a>
</p></div>
</div>

<!--PageActionFmt--><!--/PageActionFmt-->
<!--HTMLFooter-->
</body>
</html>

